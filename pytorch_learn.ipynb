{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = torch.FloatTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "# Y = torch.FloatTensor([[0], [1], [1], [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0 ,0, 0, 1], [1, 0, 1, 0], [0, 1, 0, 1], [ 1, 1, 1, 1], [ 1, 1, 1, 0]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0], [1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4])\n",
      "torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = torch.nn.Linear(4, 2, bias=True)\n",
    "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
    "sigmoid = torch.nn.Sigmoid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4712],\n",
      "        [0.4649],\n",
      "        [0.4754],\n",
      "        [0.4824],\n",
      "        [0.4691]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5175],\n",
      "        [0.5117],\n",
      "        [0.5229],\n",
      "        [0.5320],\n",
      "        [0.5171]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5454],\n",
      "        [0.5409],\n",
      "        [0.5517],\n",
      "        [0.5624],\n",
      "        [0.5473]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5619],\n",
      "        [0.5591],\n",
      "        [0.5688],\n",
      "        [0.5808],\n",
      "        [0.5661]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5715],\n",
      "        [0.5706],\n",
      "        [0.5790],\n",
      "        [0.5919],\n",
      "        [0.5781]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5771],\n",
      "        [0.5781],\n",
      "        [0.5849],\n",
      "        [0.5987],\n",
      "        [0.5859]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5803],\n",
      "        [0.5832],\n",
      "        [0.5885],\n",
      "        [0.6029],\n",
      "        [0.5913]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5820],\n",
      "        [0.5868],\n",
      "        [0.5905],\n",
      "        [0.6056],\n",
      "        [0.5952]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5829],\n",
      "        [0.5895],\n",
      "        [0.5916],\n",
      "        [0.6074],\n",
      "        [0.5982]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.5833],\n",
      "        [0.5917],\n",
      "        [0.5923],\n",
      "        [0.6086],\n",
      "        [0.6006]], grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for step in range(10):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = model(X)\n",
    "    \n",
    "    cost = criterion(outputs, Y)\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(outputs)\n",
    "#     if step % 10 == 0:\n",
    "#         print('%3d :  %15.15f' % (step, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bool__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__']"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(cost.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0026797030586749315"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(5,3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([5,3]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7498, 0.2713, 0.8445, 0.4266, 0.8765, 0.7194, 0.0414, 0.6864],\n",
      "        [0.2236, 0.7570, 0.7688, 0.8727, 0.1917, 0.7004, 0.4900, 0.9511],\n",
      "        [0.4799, 0.4813, 0.9534, 0.0219, 0.7011, 0.0798, 0.6036, 0.2494],\n",
      "        [0.0831, 0.0113, 0.2979, 0.0697, 0.2446, 0.7740, 0.9849, 0.2773],\n",
      "        [0.4364, 0.7781, 0.9398, 0.7830, 0.5841, 0.4903, 0.5574, 0.3866],\n",
      "        [0.4371, 0.3655, 0.4736, 0.4442, 0.0931, 0.1161, 0.7304, 0.5809],\n",
      "        [0.7444, 0.7141, 0.5376, 0.6645, 0.9232, 0.9526, 0.1971, 0.5768],\n",
      "        [0.0461, 0.5689, 0.3513, 0.6035, 0.2579, 0.0098, 0.1756, 0.0420]])\n",
      "tensor([[0.7028, 0.0933, 0.7392, 0.0973, 0.9493, 0.5114, 0.6881, 0.5000],\n",
      "        [0.3262, 0.8320, 0.6028, 0.7960, 0.9998, 0.6076, 0.2729, 0.2324],\n",
      "        [0.0585, 0.6092, 0.9306, 0.6421, 0.9678, 0.1625, 0.9612, 0.1957],\n",
      "        [0.6328, 0.8345, 0.7032, 0.4793, 0.5313, 0.8327, 0.0115, 0.5933],\n",
      "        [0.9322, 0.7380, 0.4564, 0.9222, 0.7767, 0.9921, 0.1870, 0.2133],\n",
      "        [0.5627, 0.2995, 0.2135, 0.7704, 0.1568, 0.5402, 0.1848, 0.5555],\n",
      "        [0.7156, 0.9237, 0.6982, 0.1452, 0.4727, 0.6717, 0.7541, 0.8281],\n",
      "        [0.2548, 0.1181, 0.2941, 0.1343, 0.3012, 0.6441, 0.2369, 0.4449]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.rand(8,8)\n",
    "t2  = torch.rand(8,8)\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.add(t1,t2).numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(torch.add(t1,t2).data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = torch.rand(1,1)\n",
    "type(t3.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0071]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(1, requires_grad=True)\n",
    "y = x + 2\n",
    "z = y*y*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3903], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.FloatTensor([2, 2, 3, 4])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4,1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=True)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[-0.1396, -0.5387]], requires_grad=True), Parameter containing:\n",
      "tensor([0.1532], requires_grad=True)]\n",
      "tensor([[ 0.1532],\n",
      "        [ 0.0137],\n",
      "        [-0.3855],\n",
      "        [-0.5251]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0,0], [1,0], [0,1], [1,1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "print(net)\n",
    "print(list(net.parameters()))\n",
    "print(net(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def criterion(out, label):\n",
    "    return (label-out)**2\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.2, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in range(101):\n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(net(X), Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if step % 10 == 0:\n",
    "        print(step, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinki\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7374303936958313\n",
      "100 0.028277577832341194\n",
      "200 0.007721865549683571\n",
      "300 0.004015292506664991\n",
      "400 0.002541970694437623\n",
      "500 0.001782441744580865\n",
      "600 0.0013313121162354946\n",
      "700 0.001038009999319911\n",
      "800 0.0008349800482392311\n",
      "900 0.0006877400446683168\n",
      "1000 0.0005770643474534154\n",
      "1100 0.0004914997844025493\n",
      "1200 0.0004237619286868721\n",
      "1300 0.00036919440026395023\n",
      "1400 0.0003243655664846301\n",
      "1500 0.0002871568431146443\n",
      "1600 0.0002558528503868729\n",
      "1700 0.00022924551740288734\n",
      "1800 0.00020641015726141632\n",
      "1900 0.00018670555436983705\n",
      "2000 0.0001694905513431877\n",
      "2100 0.00015443704614881426\n",
      "2200 0.00014115743397269398\n",
      "2300 0.000129413150716573\n",
      "2400 0.00011890604946529493\n",
      "2500 0.00010954666504403576\n",
      "2600 0.00010112629388459027\n",
      "2700 9.354059875477105e-05\n",
      "2800 8.667031215736642e-05\n",
      "2900 8.048561721807346e-05\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0 ,0, 0, 1], [1,0, 1, 0], [0, 1, 0, 1], [ 1,1, 1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import grad\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 2)\n",
    "        self.l2 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.l1(x))\n",
    "        return F.sigmoid(self.l2(x))\n",
    "\n",
    "    \n",
    "model = Net()\n",
    " \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "for step in range(3000):    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    \n",
    "    cost = criterion(outputs, Y)\n",
    "\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, cost.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7222810983657837\n",
      "100 28.680775746703148\n",
      "200 30.763062061741948\n",
      "300 31.69033985165879\n",
      "400 32.24462233716622\n",
      "500 32.621491072000936\n",
      "600 32.897590091452\n",
      "700 33.110034234588966\n",
      "800 33.27928574208636\n",
      "900 33.41767428664025\n",
      "1000 33.533128836075775\n",
      "1100 33.631008550466504\n",
      "1200 33.71508299082052\n",
      "1300 33.788089165929705\n",
      "1400 33.852067609492224\n",
      "1500 33.908575845940504\n",
      "1600 33.95882451770012\n",
      "1700 34.003770571842324\n",
      "1800 34.044181314413436\n",
      "1900 34.08068209281191\n",
      "2000 34.11378374620108\n",
      "2100 34.143913468986284\n",
      "2200 34.17142703590798\n",
      "2300 34.19662608805811\n",
      "2400 34.21976672623714\n",
      "2500 34.24106841548928\n",
      "2600 34.26072091946844\n",
      "2700 34.278888461805764\n",
      "2800 34.29571592893626\n",
      "2900 34.311327336137765\n"
     ]
    }
   ],
   "source": [
    "X = torch.FloatTensor([[0 ,0, 0, 1], [1,0, 1, 0], [0, 1, 0, 1], [ 1,1, 1, 1]])\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]])\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.autograd import grad\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = nn.Linear(4, 2)\n",
    "        self.l2 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.l1(x))\n",
    "        return F.sigmoid(self.l2(x))\n",
    "\n",
    "    \n",
    "model = Net()\n",
    " \n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "costs = 0\n",
    "for step in range(3000):    \n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    \n",
    "    cost = criterion(outputs, Y)\n",
    "\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    costs += cost.item()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        print(step, costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 1\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8., 8.],\n",
      "        [8., 8.]], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = 2*(y**2)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as tr\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install --trusted-host pypi.python.org --trusted-host files.pythonhosted.org --trusted-host pypi.org --upgrade pip\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transf = tr.Compose([tr.ToTensor(), tr.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transf)\n",
    "\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plan', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.58-cp38-cp38-win_amd64.whl (35.1 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\shinki\\appdata\\roaming\\python\\python38\\site-packages (from opencv-python) (1.17.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.58\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1759108b430>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# from PIL import Image\n",
    "\n",
    "# im = imwrite(torch.permute(images[0], (0,1,2)).numpy(), 'test.png')\n",
    "# imread('test.png').imshow()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16*5*5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "net = Net()     \n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(10):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for xx, yy in trainloader :\n",
    "        # xx, yy는 64개만 받는다.\n",
    "        y_pred = net(xx)\n",
    "        loss = loss_fn(y_pred, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    losses.append(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[176.66810087580234,\n",
       " 156.5924057494849,\n",
       " 169.15182934328914,\n",
       " 157.79765265295282,\n",
       " 153.2742952434346,\n",
       " 162.49799297377467,\n",
       " 155.7386578740552,\n",
       " 166.10457346960902,\n",
       " 160.92301862640306,\n",
       " 156.38024529395625]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (CIFAR10, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mCIFAR10\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mCIFAR10\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-2b83478ea082>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mY_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'actual'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-43-c4005e93607b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    440\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m--> 442\u001b[1;33m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[0;32m    443\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (CIFAR10, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, tuple of ints padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mCIFAR10\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n * (Tensor input, Tensor weight, Tensor bias, tuple of ints stride, str padding, tuple of ints dilation, int groups)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mCIFAR10\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mParameter\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[31;1mtuple\u001b[0m, \u001b[32;1mint\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "X = trainset\n",
    "Y_pred = net(X).detach().numpy()\n",
    "yhat = torch.argmax(net(X).detach(), 1).numpy()\n",
    "pd.crosstab(pd.Series(yhat, name='predict'), pd.Series(Y, name='actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_MultiProcessingDataLoaderIter' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f05dbbf80389>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataiter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: '_MultiProcessingDataLoaderIter' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "for i in dataiter:\n",
    "    i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2acc8e3b2fdf4025bcea67a43d307278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=26421880.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f396c0ad22421d98bdd28fceebba39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=29515.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e4f237ce0c4c22823f575879f89e30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=4422102.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e46be396f1441987b39dc43a4cf249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "# 독립변수, 종속변수 분리\n",
    "\n",
    "X = digits.data\n",
    "Y = digits.target\n",
    "# Numpy의 ndarray를 파이토치의 텐서로 변환\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797, 64])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  5.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1.,  ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2.,  ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10.,  ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "# Dataset 작성\n",
    "ds = TensorDataset(X, Y)\n",
    "# 순서로 섞어서 64개씩 데이터를 변환하는 DataLoader 작성\n",
    "loader = DataLoader(ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 10))\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for xx, yy in loader :\n",
    "        # xx, yy는 64개만 받는다.\n",
    "        y_pred = net(xx)\n",
    "        loss = loss_fn(y_pred, yy)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    losses.append(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    67.820218\n",
      "1    53.055021\n",
      "2    38.456911\n",
      "3    22.175605\n",
      "4    13.149794\n",
      "dtype: float64\n",
      "0    0.000025\n",
      "1    0.000025\n",
      "2    0.000024\n",
      "3    0.000024\n",
      "4    0.000027\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "print(pd.Series(losses[:5]))\n",
    "print(pd.Series(losses[-5:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1797])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = net(X).detach().numpy()\n",
    "\n",
    "yhat = torch.argmax(net(X).detach(), 1).numpy()\n",
    "\n",
    "pd.crosstab(pd.Series(yhat, name='predict'), pd.Series(Y, name='actual'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  5.,  ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., 10.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  ..., 16.,  9.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  1.,  ...,  6.,  0.,  0.],\n",
       "        [ 0.,  0.,  2.,  ..., 12.,  0.,  0.],\n",
       "        [ 0.,  0., 10.,  ..., 12.,  1.,  0.]])"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 34.890896  , -92.98293   , -24.290007  , ..., -23.130754  ,\n",
       "        -45.564533  , -28.944653  ],\n",
       "       [-26.353645  ,  31.332705  , -19.967237  , ..., -25.780468  ,\n",
       "         -3.102229  , -32.255405  ],\n",
       "       [  1.7789223 ,  -8.284757  ,  29.133259  , ..., -29.048021  ,\n",
       "          4.3590245 , -31.827084  ],\n",
       "       ...,\n",
       "       [-18.490685  , -23.07333   , -20.859543  , ..., -44.104553  ,\n",
       "         32.342163  , -34.90446   ],\n",
       "       [ -0.32372507, -48.420486  , -25.023777  , ..., -22.930666  ,\n",
       "          7.523018  ,  35.879704  ],\n",
       "       [-13.196332  , -41.677917  , -22.576817  , ..., -49.82823   ,\n",
       "         31.663778  ,  -6.0430646 ]], dtype=float32)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "action_size = env.action_space.n\n",
    "state_size = env.observation_space.n\n",
    "\n",
    "qtable = np.zeros((state_size, action_size))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "print(state_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_episodes = 20000       # Total episodes\n",
    "learning_rate = 0.7          # Learning rate\n",
    "max_steps = 99               # Max steps per episode\n",
    "gamma = 0.95                 # Discounting rate\n",
    "\n",
    "# Exploration parameters\n",
    "epsilon = 1.0                 # Exploration rate\n",
    "max_epsilon = 1.0             # Exploration probability at start\n",
    "min_epsilon = 0.01            # Minimum exploration probability \n",
    "decay_rate = 0.005            # Exponential decay rate for exploration prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.5049\n",
      "[[5.90214430e-02 5.96016129e-02 6.30973513e-02 4.91897494e-02]\n",
      " [7.79433794e-03 1.35913412e-02 2.56028304e-02 5.93680133e-02]\n",
      " [8.79782701e-03 8.01597169e-03 1.61513296e-02 3.24315082e-02]\n",
      " [9.14976084e-03 7.95724931e-03 2.13698905e-02 2.57136070e-02]\n",
      " [7.68854284e-02 1.79239904e-03 5.58151295e-02 2.82900222e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.62865789e-02 1.09249857e-03 5.36263676e-04 5.00695965e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [2.55247862e-02 3.46301033e-02 4.01390375e-02 2.76335897e-01]\n",
      " [3.12829726e-02 5.65531782e-01 2.75624191e-03 2.59268213e-02]\n",
      " [8.21247667e-01 1.22680137e-02 1.05907683e-02 1.76096242e-02]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [5.75479251e-04 1.46629327e-01 8.29229368e-01 5.06019823e-02]\n",
      " [1.95105572e-01 9.80534500e-01 1.65741304e-01 2.78423743e-01]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "rewards = []\n",
    "\n",
    "# 2 For life or until learning is stopped\n",
    "for episode in range(total_episodes):\n",
    "    # Reset the environment\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    total_rewards = 0\n",
    "    \n",
    "    for step in range(max_steps):\n",
    "        # 3. Choose an action a in the current world state (s)\n",
    "        ## First we randomize a number\n",
    "        exp_exp_tradeoff = random.uniform(0, 1)\n",
    "        \n",
    "        ## If this number > greater than epsilon --> exploitation (taking the biggest Q value for this state)\n",
    "        if exp_exp_tradeoff > epsilon:\n",
    "            action = np.argmax(qtable[state,:])\n",
    "            #print(exp_exp_tradeoff, \"action\", action)\n",
    "\n",
    "        # Else doing a random choice --> exploration\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "            #print(\"action random\", action)\n",
    "            \n",
    "        \n",
    "        # Take the action (a) and observe the outcome state(s') and reward (r)\n",
    "        new_state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Update Q(s,a):= Q(s,a) + lr [R(s,a) + gamma * max Q(s',a') - Q(s,a)]\n",
    "        # qtable[new_state,:] : all the actions we can take from new state\n",
    "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * np.max(qtable[new_state, :]) - qtable[state, action])\n",
    "        \n",
    "        total_rewards += reward\n",
    "        \n",
    "        # Our new state is state\n",
    "        state = new_state\n",
    "        \n",
    "        # If done (if we're dead) : finish episode\n",
    "        if done == True: \n",
    "            break\n",
    "        \n",
    "    # Reduce epsilon (because we need less and less exploration)\n",
    "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode) \n",
    "    rewards.append(total_rewards)\n",
    "    \n",
    "\n",
    "print (\"Score over time: \" +  str(sum(rewards)/total_episodes))\n",
    "print(qtable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : 2\n",
      "2 : 3\n",
      "3 : 3\n",
      "4 : 3\n",
      "5 : 0\n",
      "6 : 0\n",
      "7 : 0\n",
      "8 : 0\n",
      "9 : 3\n",
      "10 : 1\n",
      "11 : 0\n",
      "12 : 0\n",
      "13 : 0\n",
      "14 : 2\n",
      "15 : 1\n",
      "16 : 0\n"
     ]
    }
   ],
   "source": [
    "# 0 : LEFT, 1 : DOWN, 2: RIGHT, 3: UP\n",
    "# actions = {\n",
    "#     'Left': 0,\n",
    "#     'Down': 1,\n",
    "#     'Right': 2, \n",
    "#     'Up': 3\n",
    "# }\n",
    "for state in range(16):\n",
    "    print(state +1,':', np.argmax(qtable[state,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************\n",
      "EPISODE  0\n",
      "  (Left)\n",
      "SFFF\n",
      "F\u001b[41mH\u001b[0mFH\n",
      "FFFH\n",
      "HFFG\n",
      "We fell into a hole ☠️\n",
      "Number of steps 15\n",
      "****************************************************\n",
      "EPISODE  1\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "We reached our Goal 🏆\n",
      "Number of steps 24\n",
      "****************************************************\n",
      "EPISODE  2\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "We reached our Goal 🏆\n",
      "Number of steps 50\n",
      "****************************************************\n",
      "EPISODE  3\n",
      "****************************************************\n",
      "EPISODE  4\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "We reached our Goal 🏆\n",
      "Number of steps 13\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "for episode in range(5):\n",
    "    state = env.reset()\n",
    "    step = 0\n",
    "    done = False\n",
    "    print(\"****************************************************\")\n",
    "    print(\"EPISODE \", episode)\n",
    "\n",
    "    for step in range(max_steps):\n",
    "        \n",
    "        # Take the action (index) that have the maximum expected future reward given that state\n",
    "        action = np.argmax(qtable[state,:])\n",
    "        \n",
    "        new_state, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            # Here, we decide to only print the last state (to see if our agent is on the goal or fall into an hole)\n",
    "            env.render()\n",
    "            if new_state == 15:\n",
    "                print(\"We reached our Goal 🏆\")\n",
    "            else:\n",
    "                print(\"We fell into a hole ☠️\")\n",
    "            \n",
    "            # We print the number of step it took.\n",
    "            print(\"Number of steps\", step)\n",
    "            \n",
    "            break\n",
    "        state = new_state\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__enter__',\n",
       " '__eq__',\n",
       " '__exit__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_action_space',\n",
       " '_elapsed_steps',\n",
       " '_max_episode_steps',\n",
       " '_metadata',\n",
       " '_observation_space',\n",
       " '_reward_range',\n",
       " 'action_space',\n",
       " 'class_name',\n",
       " 'close',\n",
       " 'compute_reward',\n",
       " 'env',\n",
       " 'metadata',\n",
       " 'observation_space',\n",
       " 'render',\n",
       " 'reset',\n",
       " 'reward_range',\n",
       " 'seed',\n",
       " 'spec',\n",
       " 'step',\n",
       " 'unwrapped']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### CartPole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v0').unwrapped\n",
    "\n",
    "# matplotlib 설정\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "# GPU를 사용할 경우\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"transition 저장\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Linear 입력의 연결 숫자는 conv2d 계층의 출력과 입력 이미지의 크기에\n",
    "        # 따라 결정되기 때문에 따로 계산을 해야합니다.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # 최적화 중에 다음 행동을 결정하기 위해서 하나의 요소 또는 배치를 이용해 호촐됩니다.\n",
    "    # ([[left0exp,right0exp]...]) 를 반환합니다.\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shinki\\Anaconda3\\lib\\site-packages\\torchvision\\transforms\\transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "C:\\Users\\shinki\\Anaconda3\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 스레드 모드가 설정된 후에는 바꿀 수 없습니다\n",
      "  warnings.warn(str(err))\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['normal'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # gym이 요청한 화면은 400x600x3 이지만, 가끔 800x1200x3 처럼 큰 경우가 있습니다.\n",
    "    # 이것을 Torch order (CHW)로 변환한다.\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # 카트는 아래쪽에 있으므로 화면의 상단과 하단을 제거하십시오.\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # 카트를 중심으로 정사각형 이미지가 되도록 가장자리를 제거하십시오.\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # float 으로 변환하고,  rescale 하고, torch tensor 로 변환하십시오.\n",
    "    # (이것은 복사를 필요로하지 않습니다)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # 크기를 수정하고 배치 차원(BCHW)을 추가하십시오.\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# AI gym에서 반환된 형태를 기반으로 계층을 초기화 하도록 화면의 크기를\n",
    "# 가져옵니다. 이 시점에 일반적으로 3x40x90 에 가깝습니다.\n",
    "# 이 크기는 get_screen()에서 고정, 축소된 렌더 버퍼의 결과입니다.\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# gym 행동 공간에서 행동의 숫자를 얻습니다.\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max (1)은 각 행의 가장 큰 열 값을 반환합니다.\n",
    "            # 최대 결과의 두번째 열은 최대 요소의 주소값이므로,\n",
    "            # 기대 보상이 더 큰 행동을 선택할 수 있습니다.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # 100개의 에피소드 평균을 가져 와서 도표 그리기\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # 도표가 업데이트되도록 잠시 멈춤\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). 이것은 batch-array의 Transitions을 Transition의 batch-arrays로\n",
    "    # 전환합니다.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # 최종이 아닌 상태의 마스크를 계산하고 배치 요소를 연결합니다\n",
    "    # (최종 상태는 시뮬레이션이 종료 된 이후의 상태)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Q(s_t, a) 계산 - 모델이 Q(s_t)를 계산하고, 취한 행동의 열을 선택합니다.\n",
    "    # 이들은 policy_net에 따라 각 배치 상태에 대해 선택된 행동입니다.\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # 모든 다음 상태를 위한 V(s_{t+1}) 계산\n",
    "    # non_final_next_states의 행동들에 대한 기대값은 \"이전\" target_net을 기반으로 계산됩니다.\n",
    "    # max(1)[0]으로 최고의 보상을 선택하십시오.\n",
    "    # 이것은 마스크를 기반으로 병합되어 기대 상태 값을 갖거나 상태가 최종인 경우 0을 갖습니다.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # 기대 Q 값 계산\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Huber 손실 계산\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # 모델 최적화\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_episodes = 50\n",
    "for i_episode in range(num_episodes):\n",
    "    # 환경과 상태 초기화\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # 행동 선택과 수행\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # 새로운 상태 관찰\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # 메모리에 변이 저장\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # 다음 상태로 이동\n",
    "        state = next_state\n",
    "\n",
    "        # (정책 네트워크에서) 최적화 한단계 수행\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # 목표 네트워크 업데이트, 모든 웨이트와 바이어스 복사\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### PangYoLap DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_episode :50, score : 10.9, n_buffer : 544, eps : 7.8%\n",
      "n_episode :100, score : 10.5, n_buffer : 1070, eps : 7.5%\n",
      "n_episode :150, score : 10.9, n_buffer : 1615, eps : 7.3%\n",
      "n_episode :200, score : 10.3, n_buffer : 2131, eps : 7.0%\n",
      "n_episode :250, score : 11.9, n_buffer : 2724, eps : 6.8%\n",
      "n_episode :300, score : 9.6, n_buffer : 3202, eps : 6.5%\n",
      "n_episode :350, score : 10.6, n_buffer : 3733, eps : 6.2%\n",
      "n_episode :400, score : 11.4, n_buffer : 4303, eps : 6.0%\n",
      "n_episode :450, score : 12.5, n_buffer : 4930, eps : 5.8%\n",
      "n_episode :500, score : 47.2, n_buffer : 7288, eps : 5.5%\n",
      "n_episode :550, score : 85.5, n_buffer : 11561, eps : 5.3%\n",
      "n_episode :600, score : 124.5, n_buffer : 17787, eps : 5.0%\n",
      "n_episode :650, score : 122.0, n_buffer : 23888, eps : 4.8%\n",
      "n_episode :700, score : 248.8, n_buffer : 36326, eps : 4.5%\n",
      "n_episode :750, score : 307.0, n_buffer : 50000, eps : 4.2%\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#Hyperparameters\n",
    "learning_rate = 0.0005\n",
    "gamma         = 0.98\n",
    "buffer_limit  = 50000\n",
    "batch_size    = 32\n",
    "\n",
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n): # 버퍼에서 샘플링\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)   \n",
    "        self.fc3 = nn.Linear(64, 2)\n",
    "\n",
    "    def forward(self, x): # Q Value 리턴 (음수가 될 수 도 있음)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))    \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "      \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random() # 0 ~ 1 \n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,1)\n",
    "        else : \n",
    "            return out.argmax().item()\n",
    "            \n",
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s, a, r, s_prime, done_mask = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q(s) # input size (32,4) return size (32,2)\n",
    "        q_a = q_out.gather(1, a) # 취한 액션의 큐값만 골라냄 (32,1)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "q = Qnet()\n",
    "q_target = Qnet()\n",
    "q_target.load_state_dict(q.state_dict())\n",
    "memory = ReplayBuffer()\n",
    "\n",
    "print_interval = 50\n",
    "score = 0.0  \n",
    "optimizer = optim.Adam(q.parameters(), lr=learning_rate) # q_target 은 업데이트 안 함!\n",
    "\n",
    "for n_epi in range(2500):\n",
    "    epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "\n",
    "    while not done:\n",
    "        a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "        s_prime, r, done, info = env.step(a)\n",
    "        done_mask = 0.0 if done else 1.0\n",
    "        memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "        s = s_prime\n",
    "\n",
    "        score += r\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    if memory.size()>2000:\n",
    "        train(q, q_target, memory, optimizer)\n",
    "\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\n",
    "        q_target.load_state_dict(q.state_dict()) # 타겟 네트워크 업데이트 (20 번 에피소드 마다)\n",
    "        print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(n_epi, score/print_interval, memory.size(), epsilon*100))                \n",
    "        \n",
    "        if (score/print_interval) > 300:\n",
    "            break\n",
    "            \n",
    "        score = 0.0\n",
    "        \n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\shinki\\\\OneDrive - Novelis Inc\\\\Documents\\\\Data Science\\\\10. Learning\\\\7. RL\\\\q_target'\n",
    "# torch.save(q_target.state_dict(), path) # save weights only\n",
    "torch.save(q_target, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_target = torch.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 395 timesteps\n",
      "Episode finished after 500 timesteps\n",
      "Episode finished after 483 timesteps\n",
      "Episode finished after 500 timesteps\n",
      "Episode finished after 484 timesteps\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    for t in range(550):\n",
    "        time.sleep(0.01)\n",
    "        env.render()\n",
    "        action = q_target(torch.Tensor(observation)).argmax().item() \n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            time.sleep(1)\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 11 timesteps\n",
      "Episode finished after 36 timesteps\n",
      "Episode finished after 14 timesteps\n",
      "Episode finished after 19 timesteps\n",
      "Episode finished after 11 timesteps\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gym\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "\n",
    "for i_episode in range(5):\n",
    "    observation = env.reset()\n",
    "    for t in range(300):\n",
    "        time.sleep(0.01)\n",
    "        env.render()\n",
    "#         action = env.action_space.sample()\n",
    "        action = random.randint(0,1)\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            time.sleep(1)\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.35309133  0.5595656  -0.0241827  -0.9231632 ] 1.0\n"
     ]
    }
   ],
   "source": [
    "observation, reward, done, info = env.step(1)\n",
    "print(observation, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.01553766  0.18166435 -0.0057572  -0.3242021 ] 1.0\n",
      "[-0.01190438  0.3768678  -0.01224125 -0.618695  ] 1.0\n",
      "[-0.00436702  0.18191895 -0.02461515 -0.3298925 ] 1.0\n",
      "[-0.00072864  0.3773825  -0.03121299 -0.63023514] 1.0\n",
      "[ 0.00681901  0.18270968 -0.0438177  -0.34754324] 1.0\n",
      "[ 0.0104732   0.37842658 -0.05076856 -0.65371513] 1.0\n",
      "[ 0.01804173  0.18404695 -0.06384286 -0.3774409 ] 1.0\n",
      "[ 0.02172267 -0.01011292 -0.07139168 -0.10555146] 1.0\n",
      "[ 0.02152042 -0.20414302 -0.07350271  0.16378099] 1.0\n",
      "[ 0.01743755 -0.00805003 -0.07022709 -0.15115464] 1.0\n",
      "[ 0.01727655  0.18800358 -0.07325018 -0.46513996] 1.0\n",
      "[ 0.02103662  0.38408    -0.08255298 -0.7799822 ] 1.0\n",
      "[ 0.02871823  0.19018413 -0.09815263 -0.51437193] 1.0\n",
      "[ 0.03252191 -0.00342844 -0.10844006 -0.25416142] 1.0\n",
      "[ 0.03245334 -0.1968484  -0.1135233   0.00244542] 1.0\n",
      "[ 2.85163708e-02 -2.96875223e-04 -1.13474384e-01 -3.23788345e-01] 1.0\n",
      "[ 0.02851043  0.19624257 -0.11995015 -0.6499914 ] 1.0\n",
      "[ 0.03243528  0.39281306 -0.13294998 -0.9779093 ] 1.0\n",
      "[ 0.04029154  0.19970003 -0.15250817 -0.72976834] 1.0\n",
      "[ 0.04428555  0.39656404 -0.16710353 -1.0663006 ] 1.0\n"
     ]
    }
   ],
   "source": [
    "observation = env.reset()\n",
    "for i in range(20):\n",
    "\n",
    "    action = random.randint(0,1)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    print(observation, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
